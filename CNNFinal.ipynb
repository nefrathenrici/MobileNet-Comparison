{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "## mnsist classifier using pytorch\n",
    "\n",
    "adapted from https://pytorch.org/tutorials/beginner/nn_tutorial.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Where to run this notebook\n",
    "\n",
    "You can run this locally; i.e. not on paperspace. You will need to install pytorch. You can find instructions here: \n",
    "https://pytorch.org/\n",
    "\n",
    "This notebook should be uploaded to a directory that contains a data subdirectory. If needed, create the data subdirectory manually."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get the mnist data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "\n",
    "#Get Resnet\n",
    "network = models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library Imports\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch as torch\n",
    "import numpy as np\n",
    "import os\n",
    "    \n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import gzip\n",
    "import matplotlib.image as mpimg \n",
    "import matplotlib.pyplot as plt \n",
    "from PIL import Image\n",
    "import glob\n",
    "import torchvision.transforms as transforms\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables/functions for help reading the data\n",
    "datapath = \"./tiny-imagenet-200/\"\n",
    "trainpath = datapath + \"train/\"\n",
    "classIDs = os.listdir(trainpath)\n",
    "classIDDict = {}\n",
    "for i in range(len(classIDs)):\n",
    "    classIDDict[classIDs[i]] = i\n",
    "\n",
    "classCount = len(classIDs)\n",
    "sourceDim = 64\n",
    "targetDim = 224\n",
    "channels = 3\n",
    "\n",
    "trainPerClass = 450   #500 original\n",
    "testPerClass = 10\n",
    "validPerClass = 20\n",
    "\n",
    "imageCountTr = classCount  * trainPerClass\n",
    "imageCountTs = classCount  * testPerClass\n",
    "imageCountV = classCount  * validPerClass\n",
    "\n",
    "# Turn single-channel images into 3-channel images\n",
    "def stackImage(image):\n",
    "    return np.stack((im,)*channels, axis=-1)\n",
    "\n",
    "# Helper function for resizing and normalizing images\n",
    "def processImage(image):\n",
    "    if (len(image.shape) < channels):\n",
    "        image = stackImage(image)\n",
    "    asfloat = image.astype('float32')\n",
    "    resized = cv2.resize(asfloat, dsize=(targetDim,targetDim), interpolation=cv2.INTER_CUBIC)\n",
    "    rolled = np.rollaxis(resized, 2, 0)\n",
    "    tensor = torch.tensor(rolled)\n",
    "    normalized = normalize(tensor)\n",
    "    numpied = normalized.numpy()[:,:,:]\n",
    "    return numpied\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: 0\n",
      "Class: 1\n",
      "Class: 2\n",
      "Class: 3\n",
      "Class: 4\n",
      "Class: 5\n",
      "Class: 6\n",
      "Class: 7\n",
      "Class: 8\n",
      "Class: 9\n",
      "Class: 10\n",
      "Class: 11\n",
      "Class: 12\n",
      "Class: 13\n",
      "Class: 14\n",
      "Class: 15\n",
      "Class: 16\n",
      "Class: 17\n",
      "Class: 18\n",
      "Class: 19\n",
      "Class: 20\n",
      "Class: 21\n",
      "Class: 22\n",
      "Class: 23\n",
      "Class: 24\n",
      "Class: 25\n",
      "Class: 26\n",
      "Class: 27\n",
      "Class: 28\n",
      "Class: 29\n",
      "Class: 30\n",
      "Class: 31\n",
      "Class: 32\n",
      "Class: 33\n",
      "Class: 34\n",
      "Class: 35\n",
      "Class: 36\n",
      "Class: 37\n",
      "Class: 38\n",
      "Class: 39\n",
      "Class: 40\n",
      "Class: 41\n",
      "Class: 42\n",
      "Class: 43\n",
      "Class: 44\n",
      "Class: 45\n",
      "Class: 46\n",
      "Class: 47\n",
      "Class: 48\n",
      "Class: 49\n",
      "Class: 50\n",
      "Class: 51\n",
      "Class: 52\n",
      "Class: 53\n",
      "Class: 54\n",
      "Class: 55\n",
      "Class: 56\n",
      "Class: 57\n",
      "Class: 58\n",
      "Class: 59\n",
      "Class: 60\n",
      "Class: 61\n",
      "Class: 62\n",
      "Class: 63\n",
      "Class: 64\n",
      "Class: 65\n",
      "Class: 66\n",
      "Class: 67\n",
      "Class: 68\n",
      "Class: 69\n",
      "Class: 70\n",
      "Class: 71\n",
      "Class: 72\n",
      "Class: 73\n",
      "Class: 74\n",
      "Class: 75\n",
      "Class: 76\n",
      "Class: 77\n",
      "Class: 78\n",
      "Class: 79\n",
      "Class: 80\n",
      "Class: 81\n",
      "Class: 82\n",
      "Class: 83\n",
      "Class: 84\n",
      "Class: 85\n",
      "Class: 86\n",
      "Class: 87\n",
      "Class: 88\n",
      "Class: 89\n",
      "Class: 90\n",
      "Class: 91\n",
      "Class: 92\n",
      "Class: 93\n",
      "Class: 94\n",
      "Class: 95\n",
      "Class: 96\n",
      "Class: 97\n",
      "Class: 98\n",
      "Class: 99\n",
      "Class: 100\n",
      "Class: 101\n",
      "Class: 102\n",
      "Class: 103\n",
      "Class: 104\n",
      "Class: 105\n",
      "Class: 106\n",
      "Class: 107\n",
      "Class: 108\n",
      "Class: 109\n",
      "Class: 110\n",
      "Class: 111\n",
      "Class: 112\n",
      "Class: 113\n",
      "Class: 114\n",
      "Class: 115\n",
      "Class: 116\n",
      "Class: 117\n",
      "Class: 118\n",
      "Class: 119\n",
      "Class: 120\n",
      "Class: 121\n",
      "Class: 122\n",
      "Class: 123\n",
      "Class: 124\n",
      "Class: 125\n",
      "Class: 126\n",
      "Class: 127\n",
      "Class: 128\n",
      "Class: 129\n",
      "Class: 130\n",
      "Class: 131\n",
      "Class: 132\n",
      "Class: 133\n",
      "Class: 134\n",
      "Class: 135\n",
      "Class: 136\n",
      "Class: 137\n",
      "Class: 138\n",
      "Class: 139\n",
      "Class: 140\n",
      "Class: 141\n",
      "Class: 142\n",
      "Class: 143\n",
      "Class: 144\n",
      "Class: 145\n",
      "Class: 146\n",
      "Class: 147\n",
      "Class: 148\n",
      "Class: 149\n",
      "Class: 150\n",
      "Class: 151\n",
      "Class: 152\n",
      "Class: 153\n",
      "Class: 154\n",
      "Class: 155\n",
      "Class: 156\n",
      "Class: 157\n",
      "Class: 158\n",
      "Class: 159\n",
      "Class: 160\n",
      "Class: 161\n",
      "Class: 162\n",
      "Class: 163\n",
      "Class: 164\n",
      "Class: 165\n",
      "Class: 166\n",
      "Class: 167\n",
      "Class: 168\n",
      "Class: 169\n",
      "Class: 170\n",
      "Class: 171\n",
      "Class: 172\n",
      "Class: 173\n",
      "Class: 174\n",
      "Class: 175\n",
      "Class: 176\n",
      "Class: 177\n",
      "Class: 178\n",
      "Class: 179\n",
      "Class: 180\n",
      "Class: 181\n",
      "Class: 182\n",
      "Class: 183\n",
      "Class: 184\n",
      "Class: 185\n",
      "Class: 186\n",
      "Class: 187\n",
      "Class: 188\n",
      "Class: 189\n",
      "Class: 190\n",
      "Class: 191\n",
      "Class: 192\n",
      "Class: 193\n",
      "Class: 194\n",
      "Class: 195\n",
      "Class: 196\n",
      "Class: 197\n",
      "Class: 198\n",
      "Class: 199\n"
     ]
    }
   ],
   "source": [
    "#training, test, validation data\n",
    "imagesTr = np.zeros((imageCountTr, channels, targetDim, targetDim), dtype=\"float32\")\n",
    "labelsTr = np.zeros(imageCountTr, dtype=int)\n",
    "\n",
    "imagesTs = np.zeros((imageCountTs, channels, targetDim, targetDim), dtype=\"float32\")\n",
    "labelsTs = np.zeros(imageCountTs, dtype=int)\n",
    "\n",
    "imagesV = np.zeros((imageCountV, channels, targetDim, targetDim), dtype=\"float32\")\n",
    "labelsV = np.zeros(imageCountV, dtype=int)\n",
    "\n",
    "dataset = [(imagesTr, labelsTr), (imagesTs, labelsTs), (imagesV, labelsV)]\n",
    "\n",
    "for i in range(len(classIDs)):\n",
    "    fileNames = glob.glob(trainpath+classIDs[i]+\"/images/*.JPEG\")\n",
    "    j = 0\n",
    "    for s in dataset:\n",
    "        length = int(len(s[0]) / classCount)\n",
    "        for k in range(length):\n",
    "            classIndex = j + k\n",
    "            setIndex = i * length + k\n",
    "            im = mpimg.imread(fileNames[classIndex].replace(\"\\\\\", \"/\"))\n",
    "            im = processImage(im)\n",
    "            label = i\n",
    "            s[0][setIndex] = im\n",
    "            s[1][setIndex] = label \n",
    "        j += length\n",
    "    print('Class: ' + str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data to tensor\n",
    "x_train, y_train = imagesTr, labelsTr\n",
    "x_valid, y_valid = imagesV, labelsV\n",
    "x_train, y_train, x_valid, y_valid = map(\n",
    "    torch.as_tensor, (x_train, y_train, x_valid, y_valid)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switch to GPU\n",
    "if torch.cuda.is_available(): \n",
    "    dev = \"cuda:0\" \n",
    "    device = torch.device(dev)\n",
    "    network.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensor Dataset from tensors\n",
    "train_ds = TensorDataset(x_train, y_train)\n",
    "valid_ds = TensorDataset(x_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create DataLoader\n",
    "import torch\n",
    "\n",
    "def get_data(train_ds, valid_ds, bs):\n",
    "    return (\n",
    "        DataLoader(train_ds, batch_size=bs, shuffle=True),\n",
    "        DataLoader(valid_ds, batch_size=bs * 2),\n",
    "    )\n",
    "\n",
    "class WrappedDataLoader:\n",
    "    def __init__(self, dl, func):\n",
    "        self.dl = dl\n",
    "        self.func = func\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dl)\n",
    "\n",
    "    def __iter__(self):\n",
    "        batches = iter(self.dl)\n",
    "        for b in batches:\n",
    "            yield (self.func(*b))\n",
    "            \n",
    "class Lambda(nn.Module):\n",
    "    def __init__(self, func):\n",
    "        super().__init__()\n",
    "        self.func = func\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.func(x)\n",
    "\n",
    "def preprocess1(x):\n",
    "    return x.view(-1, channels, targetDim, targetDim)\n",
    "\n",
    "def preprocess2(x, y):\n",
    "    return x.view(-1, channels, targetDim, targetDim), y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define log softmax and our model output\n",
    "\n",
    "def log_softmax(x):\n",
    "    return x - x.exp().sum(-1).log().unsqueeze(-1)\n",
    "\n",
    "# negative loss likelihood (equivalent to cross entropy)\n",
    "def nll(inp, target):\n",
    "    return -inp[range(target.shape[0]), target].mean()\n",
    "\n",
    "# Define our loss function and accuracy\n",
    "loss_func = F.cross_entropy\n",
    "def accuracy(out, yb):\n",
    "    preds = torch.argmax(out, dim=1)\n",
    "    return (preds == yb).float().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Loss for a full batch\n",
    "def loss_batch(model, loss_func, xb, yb, opt=None):\n",
    "    yb = yb.long()\n",
    "    loss = loss_func(model(xb), yb)\n",
    "\n",
    "    if opt is not None:\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "    return loss.item(), len(xb)\n",
    "\n",
    "# Fit model to data\n",
    "def fit(epochs, model, loss_func, opt, train_dl, valid_dl):\n",
    "    # Training loop\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for xb, yb in train_dl:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            loss_batch(model, loss_func, xb, yb, opt)\n",
    "\n",
    "        model.eval()\n",
    "        epoch_val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for xb, yb in valid_dl:\n",
    "                xb, yb = xb.to(device), yb.to(device)\n",
    "                val_loss, nums = loss_batch(model, loss_func, xb, yb)\n",
    "                epoch_val_loss +=  val_loss\n",
    "            epoch_val_loss /= nums\n",
    "        print(epoch, epoch_val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "bs = 32\n",
    "lr = 2.85e-3  # learning rate\n",
    "epochs = 5  # how many epochs to train for\n",
    "\n",
    "train_dl, valid_dl = get_data(train_ds, valid_ds, bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap dataloader and get parameters\n",
    "train_dl = WrappedDataLoader(train_dl, preprocess2)\n",
    "valid_dl = WrappedDataLoader(valid_dl, preprocess2)\n",
    "opt = optim.SGD(network.parameters(), lr=lr, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3.444652395322919\n",
      "1 3.0606869719922543\n",
      "2 2.9786742124706507\n"
     ]
    }
   ],
   "source": [
    "#Train Model\n",
    "fit(epochs, network, loss_func, opt, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save Network\n",
    "torch.save(network, './resnet.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc818c3cefc5431aad42bc3e1d185c49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early, the loss has diverged\n",
      "\n",
      "Learning rate search finished. See the graph with {finder_name}.plot()\n",
      "LR suggestion: steepest gradient\n",
      "Suggested LR: 2.85E-03\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Learning rate finder, used for learning rate above\n",
    "from torch_lr_finder import LRFinder\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(network.parameters(), lr=1e-7, weight_decay=1e-2)\n",
    "lr_finder = LRFinder(network, optimizer, criterion, device=dev)\n",
    "lr_finder.range_test(train_dl, end_lr=100, num_iter=100)\n",
    "lr_finder.plot() # to inspect the loss-learning rate graph\n",
    "lr_finder.reset() # to reset the model and optimizer to their initial state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See network\n",
    "network = torch.load('./resnet.pt')\n",
    "network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6322, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Compute accuracy on validation set (test set not labeled)\n",
    "def accuracy(out, yb):\n",
    "    preds = torch.argmax(out, dim=1)\n",
    "    return (preds == yb).float().mean()\n",
    "\n",
    "val_acc = 0\n",
    "counter = 0\n",
    "with torch.no_grad():\n",
    "    for xb, yb in valid_dl:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        out = network(xb)\n",
    "        val_acc += accuracy(out, yb)\n",
    "        counter += 1\n",
    "print(val_acc/counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
